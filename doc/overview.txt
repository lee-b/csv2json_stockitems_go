Overview
========

The main components here are:

   + src/lbgotest.com/lb/stockdatalib:

      This Go library provides:

         - An internal representation of StockItem objects, and associate
           datatypes such as Price values.
         - Functions for reading them from csv.Reader objects
         - MarshalJSON implementations for some types, such as Prices, to
           format them as required in JSON output.

      This library supports a streaming API, meaning that you can load one
      item at a time, work with it, and write it out.  All data does NOT
      need to be kept in memory at once.

   + csv_items_to_json:

      This command-line tool, a thin wrapper over the above library, reads
      stock items from a specifically formatted (as specified) CSV file, and
      writes them to a JSON file.  Both filenames are taken on the command
      line.


Goals
=====

* Import stock item data from CSV format

* Export stock item data to JSON format

* Extensible code (as per requirements), which I take to mean:
  - re-usable input parsing -- parsing to a usable internal data format
  - re-usable output -- output from a usable internal data format

* "Production-ready", which I take to mean:
  - sane, usable, safe, pre-parsed internal data format:
      + nil, rather than the string value "nil"
      + proper numeric values rather than unparsed string values with or
        without currency symbols
      + fixed-precision or integer format currency values, rather than
        floating point values, which may have precision problems.
  - VALIDATED data, RATHER THAN BLIND / GENERIC CONVERSION (which would have
    been much easier, faster, and more reusable, in many ways, but also less
    useful in terms of reusable INTERNAL stock item data)

* Use go standard library facilities for actual csv/json I/O (to minimise new
  code, and assist with extensibility)

* Reusable code core data model, to allow it to serve as the hub for future,
  additional import / export formats.

* Precision control in currency values, to avoid floating point precision
  issues.

* Unit-tested

* Functionally tested on actual data files

* Verified against given scenario

* Verified on larger data set, proving streaming/big data should work

* Verbose mode to assist with debugging / progress tracking, especially on
  larger data files.

* "Production-ready", although this is a vague term without knowing
  requirements of the production environment in question.  The requirements
  I've assumed are:
    + Input validation / security
    + Big data (stream-based processing rather than loading all data into
      memory at once)
    + Reliability, as specified above in terms of tests, required features,
       etc.


Non-goals & assumptions
=======================

* JSON does not have a keyword "nil", although it's supported as a string, but
  it DOES recognise the special keyword support "null".  This presents two
  options, neither of which is ideal, and so a choice had to be made:

      Choice 1:

          Ignore JSON's support for null, despite the overarching goal to
          produce a **JSON** file (as opposed to a file in a format SIMILAR
          to JSON.  Ignore Go's built-in support for marshalling structs,
          and implement a custom marshaller to output the non-compliant
          near-JSON format.  Note that this would also conflict with the goal
          of reusability, since it means having to implement custom
          JSON parsers for all output data, and might lock all future
          implementations / rewrites of this tool into creating similarly
          non-standard files.

      Choice 2:

          Assume that null was meant rather than nil in the example output
          file -- perhaps that nil was written because it is called this in
          Go, rather than JSON.  Assume that the intention is to create
          STANDARD, compatible, JSON, following established internet
          RFCs.  This would also assist with the goal of reusable code.
     
  Rather than blindly break a standard format, which, in my experience, is
  the cause of many code maintence and incompatibility issues, I have assumed
  that choice 2 was intended, and would be preferred here.

  If choice 1 was, in fact, intended, then note that this would have been
  very easy to accomplish, by implementing a MarshalJSON() method for the
  StockItem class, and adding JSON-formatted bytes manually for the overall
  object, along with calling Marshal() to obtain the bytes for subfields.
  Something similar IS done in the top-level command-line tool, to wrap the
  individual StockItems in JSON list.

  Of course, in real, day-to-day work, it would be easy to check this with
  whoever wrote the format specification.

* The sample data, provided as a PDF from Word, contained soft-hypens in place
  of ASCII minus signs.  I've assumed ASCII minus signs were intended.  If
  this is not the case, then it seems the solution would be to use Go's
  unicode Rune support to decode and check for the correct values, but this
  would add complexity, and is unlikely to fit the actual usage criteria.

* Very specific output examples are given, in a particular variant of JSON
  which uses unquoted, single-word strings, for example.  This is assumed to
  be an unimportant detail, with the files meant as an illustration of overall
  json layout (keys / values / datatypes), rather than as an exacting
  specification.

* From the sample data, it appears that stock items have at least 5 fields (up
  to price_type).  This is assumed to always be the case, since I cannot
  safely choose defaults if these fields are missing.  Empty fields are
  allowed, and (hopefully) correctly handled, though.

* The input data's "cost" field varies between beginning with a dollar sign,
  and not having a dollar sign.  It's assumed that all prices may have or not
  have dollar signs, and that, if they don't, they are parsed the same way (as
  decimal dollar values), otherwise: i.e., that "80" == "$80", "80.10" ==
  "$80.10", "80.1" == "$80.10", etc.

* Currency tracking and conversion has NOT been attempted.  The input file
  OFTEN has currency symbols, but NOT always.  Since all currencieis specified
  in the input are the same, and no currencies are specified in the output, and
  no default local currency is specified, nor any currency conversion rates,
  I assume currency is to be disregarded for the purposes of this test.

* The "quantity_on_hand" field values are assumed to be integers, since I saw
  no examples of fractional values in this field.

* Prices are assumed to have integer cents values (i.e., no fractions of a
  cent), as this fits the data presented in examples, and logically, makes
  sense for MOST retail purposes.

* Perfectly idiomatic Go (preferred style, preferred design patterns, etc.) is
  not a goal. I do not know Go yet, and researching Go idioms extensively for
  all parts of the code could take too much time for the purposes of this
  test.

  Attempts at idiomatic code HAVE been made where reasonable, though, such as
  using JSON Reader / Writer, using iota rather than simply typing values,
  etc.

* I've assumed that "modifier" entries (which are paired fields:
  modifier_1_name, and modifier_1_price, for example) can either be specified,
  or not specified, but that one field should not be present without the
  other. If this is detected during input parsing, then an error is reported.


Future improvements / wishlist
==============================

* Multiple currencies (swap out Cents for a Monetary type)
* Add input & output file buffering for improved performance
* Use Go channels to create parallel input / parsing / output, for better
  overall throughput.  To do this without a genuine need may be premature
  optimisation, however.

